[{"content":"","date":null,"permalink":"http://localhost:1313/blog/","section":"Blogs","summary":"","title":"Blogs"},{"content":"","date":null,"permalink":"http://localhost:1313/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"http://localhost:1313/","section":"Hiren Patel","summary":"","title":"Hiren Patel"},{"content":"","date":null,"permalink":"http://localhost:1313/categories/how-tos/","section":"Categories","summary":"","title":"How Tos"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/launchd/","section":"Tags","summary":"","title":"Launchd"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/logging/","section":"Tags","summary":"","title":"Logging"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/macos/","section":"Tags","summary":"","title":"MacOS"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/newsyslog/","section":"Tags","summary":"","title":"Newsyslog"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/openclaw/","section":"Tags","summary":"","title":"Openclaw"},{"content":"","date":null,"permalink":"http://localhost:1313/categories/programming/","section":"Categories","summary":"","title":"Programming"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"I noticed my OpenClaw gateway log files were growing unbounded. The service runs via launchd, and while the app has built-in log rotation, the stdout/stderr capture in the launchd plist was bypassing it entirely.\nThe Problem #When a macOS service uses StandardOutPath and StandardErrorPath in its launchd plist, those files just append forever. My logs had grown to 38MB with no mechanism to clean them up:\n$ ls -lh ~/.openclaw/logs/ -rw-r--r-- 1 clawd staff 3.9M Feb 25 17:48 gateway.log -rw-r--r-- 1 clawd staff 38M Feb 25 17:48 gateway.err.log OpenClaw\u0026rsquo;s internal logger writes date-based rotating logs to /tmp/openclaw/, but launchd\u0026rsquo;s stdout capture writes directly to the configured files, bypassing that rotation logic.\nThe Hidden Trap: When log rotation tools like newsyslog create new log files, they default to root:root ownership. If your launchd service runs as your user (not root), it suddenly can\u0026rsquo;t write to its own log files after rotation. The daemon fails to start with \u0026ldquo;Permission denied\u0026rdquo; errors, and you\u0026rsquo;re left wondering why your service won\u0026rsquo;t start.\nThe Solution: newsyslog #macOS includes newsyslog, a utility for managing log file rotation. It\u0026rsquo;s already running on your system, checking logs periodically via launchd. You just need to tell it about your custom log files.\nConfiguration #Create a config file for your service logs:\nsudo tee /etc/newsyslog.d/openclaw.conf \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; # OpenClaw gateway logs - rotate at 10MB, keep zero archives /Users/clawd/.openclaw/logs/gateway.log clawd:staff 644 0 10000 * B /Users/clawd/.openclaw/logs/gateway.err.log clawd:staff 644 0 10000 * B EOF Important: Notice the clawd:staff owner:group fields. Without these, newsyslog creates the new log files as root:root after rotation. When your launchd service tries to write to a root-owned file, it gets \u0026ldquo;Permission denied\u0026rdquo; and the daemon fails to start.\nField breakdown:\nclawd:staff — Owner and group for the log files (critical!) 644 — File permissions (owner read/write, others read-only) 0 — Number of archived files to keep (zero = just truncate) 10000 — Size threshold in KB (~10MB) * — Rotate at any time (not just specific hours) B — Treat as binary (no special encoding) What Happens Without Owner Specified #If you omit the owner:group fields, you\u0026rsquo;ll see this after newsyslog runs:\n$ ls -la ~/.openclaw/logs/ -rw-r--r-- 1 root wheel 0 Feb 25 18:30 gateway.log -rw-r--r-- 1 root wheel 0 Feb 25 18:30 gateway.err.log Then your service fails to start with errors like:\nCould not open log file /Users/clawd/.openclaw/logs/gateway.log: Permission denied Service exited with abnormal code: 1 The clawd:staff fields ensure the rotated files remain owned by your user, not root.\nReload and Verify #Tell newsyslog to reload its configuration:\nsudo killall -HUP newsyslog Check that the config loaded correctly:\nsudo newsyslog -v -f /etc/newsyslog.d/openclaw.conf Force an immediate rotation to test:\nsudo newsyslog -v -f /etc/newsyslog.d/openclaw.conf -R \u0026#34;manual\u0026#34; ~/.openclaw/logs/gateway.err.log Note: The -R flag with a requestor name is optional. Plain newsyslog -v -f /path/to/config works fine for testing.\nWhy Not Cron? #I considered a simple cron job:\n0 3 * * * truncate -s 0 ~/.openclaw/logs/gateway.log That would work, but newsyslog is the native macOS tool for this. It\u0026rsquo;s already running, already has permission handling figured out, and rotates based on file size rather than just time. If your log suddenly explodes to 500MB, newsyslog catches it on the next check cycle (every 30 minutes). Cron would wait until 3 AM.\nResult #After setup, my 38MB error log was truncated to zero bytes:\n$ ls -lh ~/.openclaw/logs/ -rw-r--r-- 1 clawd staff 4.9M Feb 25 18:02 gateway.log -rw-r--r-- 1 clawd staff 0B Feb 25 18:10 gateway.err.log No manual intervention needed going forward. When either file crosses 10MB, newsyslog truncates it automatically.\nReferences # newsyslog man page OpenClaw documentation launchd documentation ","date":"Feb 25, 2026","permalink":"http://localhost:1313/blog/macos-newsyslog-openclaw-logs/","section":"Blogs","summary":"\u003cp\u003eI noticed my \u003ca href=\"https://clawd.bot/\" target=\"_blank\" rel=\"noreferrer\"\u003eOpenClaw\u003c/a\u003e gateway log files were growing unbounded. The service runs via \u003ca href=\"https://developer.apple.com/library/archive/documentation/MacOSX/Conceptual/BPSystemStartup/Chapters/CreatingLaunchdJobs.html\" target=\"_blank\" rel=\"noreferrer\"\u003elaunchd\u003c/a\u003e, and while the app has built-in log rotation, the stdout/stderr capture in the launchd plist was bypassing it entirely.\u003c/p\u003e","title":"Using macOS newsyslog to Rotate Service Logs"},{"content":"","date":null,"permalink":"http://localhost:1313/categories/ai-automation/","section":"Categories","summary":"","title":"AI Automation"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/automation/","section":"Tags","summary":"","title":"Automation"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/claude-code/","section":"Tags","summary":"","title":"Claude Code"},{"content":"Claude Code is an impressive CLI that brings sophisticated AI-assisted coding directly into the terminal. Its TUI (Text User Interface) provides rich feedback through interactive menus, progress bars, and side-by-side diffs. However, long-running tasks present a challenge: if you need to step away from your computer, the session momentum is often lost.\nTo solve this, I’ve developed a workflow using Tmux as a shared terminal state. This allows me to hand off a live session to my Clawdbot agent and, conversely, take over a session that the agent started. It also provides a mechanism to optionally switch between different account tokens (such as a work account) on the fly.\nThe Core Concept: Persistence #The strategy relies on Tmux sessions to maintain a persistent terminal state in memory. By using named sessions, both the human and the AI agent can attach to and drive the exact same process. This ensures zero context loss when switching between \u0026ldquo;manual\u0026rdquo; and \u0026ldquo;agent\u0026rdquo; mode.\nConfiguration: Storing Account Profiles #To enable the agent to switch accounts, you can store secondary tokens in the coding-agent skill section of clawdbot.json. Using simple shorthand keys makes it easier to request them from a phone.\n\u0026#34;skills\u0026#34;: { \u0026#34;entries\u0026#34;: { \u0026#34;coding-agent\u0026#34;: { \u0026#34;env\u0026#34;: { \u0026#34;CC_ACC2_TOKEN\u0026#34;: \u0026#34;your-token-here\u0026#34; } } } } Workflow 1: Human to Agent Hand-off #When I am working at my desk and need to step away, I follow these steps:\nStart a named Tmux session:\ntmux new -s hiren-claude claude Pro-Tip: If you want to launch manually with a specific account token, use the env prefix within the Tmux command string to ensure the environment variable is correctly injected into the background session:\ntmux new -s hiren-claude -d \u0026#34;env CLAUDE_CODE_OAUTH_TOKEN=\u0026#39;your-token\u0026#39; claude\u0026#34; Request Hand-off: From WhatsApp, I tell the agent:\n\u0026ldquo;Take over session hiren-claude. Finish the refactor.\u0026rdquo;\nEnvironment Inheritance #If I start a session at my desk using export CLAUDE_CODE_OAUTH_TOKEN=..., the agent inherits that environment automatically when it takes over the Tmux pane. Keystrokes sent by the agent will be processed within that authenticated shell.\nWorkflow 2: Agent to Human Take-over #The hand-off also works in reverse. I can have the agent start a complex task while I am away:\nDefault Account Example #I can instruct the agent to start a new run using my default CLI login:\n\u0026ldquo;Start a new session hiren-claude and begin refactoring the database schema.\u0026rdquo;\nBehind the scenes, the agent runs tmux new -s hiren-claude -d \u0026quot;claude '...'\u0026quot;.\nSpecific Account Example #If I want the agent to use a specific account profile from the config:\n\u0026ldquo;Start a new session hiren-claude using cc-acc2-token and fix the memory leak.\u0026rdquo;\nThe agent then prepends the token to the execution, mapping the CC_ACC2_TOKEN from the config to the CLAUDE_CODE_OAUTH_TOKEN required by the CLI.\nHuman Take-over #When I return to my computer, I can attach to the session and take full control immediately:\ntmux attach -t hiren-claude Because Tmux lives in the background, this works even if the screen is locked, provided the computer remains awake.\nBenefits of the Tmux Bridge # Full TUI Support: Standard stdin/stdout redirection often breaks the interactive elements of Claude Code. Using Tmux preserves the full visual experience. Real-time Monitoring: I can \u0026ldquo;spectate\u0026rdquo; the work by attaching to the session via SSH from a mobile device or another terminal. Zero Friction: No need to re-authenticate or re-explain context when switching between human and AI control. Pro-Tip: Smooth Scrolling in Tmux #One common frustration when using Claude Code inside Tmux is scrolling. By default, using the mouse wheel might send \u0026ldquo;Up/Down\u0026rdquo; arrow keys, which moves the text in the entry box rather than scrolling the terminal history.\nTo fix this, you can enable Mouse Mode. Add the following to your ~/.tmux.conf file:\nset -g mouse on With this enabled, you can scroll through Claude\u0026rsquo;s responses naturally. If you don\u0026rsquo;t want to enable global mouse mode, you can always enter Copy Mode manually by pressing Ctrl-b then [. Once in copy mode, you can scroll freely; just press q to return to the prompt.\nExecution Reminders # Installation: Ensure tmux is installed via Homebrew (brew install tmux). Naming: Use consistent session names so the agent knows where to look. Power Settings: Configure your Mac to stay awake when the display is off to ensure the Tmux server remains active. By treating the terminal as a shared space, I’ve turned my AI agent into a true tag-team partner. We can hot-swap control of the keyboard and switch accounts on the fly without ever losing the \u0026ldquo;zone.\u0026rdquo;\n","date":"Jan 22, 2026","permalink":"http://localhost:1313/blog/tag-teaming-claude-code-with-ai-agent/","section":"Blogs","summary":"\u003cp\u003e\u003ca href=\"https://claude.ai/code\" target=\"_blank\" rel=\"noreferrer\"\u003eClaude Code\u003c/a\u003e is an impressive CLI that brings sophisticated AI-assisted coding directly into the terminal. Its TUI (Text User Interface) provides rich feedback through interactive menus, progress bars, and side-by-side diffs. However, long-running tasks present a challenge: if you need to step away from your computer, the session momentum is often lost.\u003c/p\u003e\n\u003cp\u003eTo solve this, I’ve developed a workflow using \u003ca href=\"https://github.com/tmux/tmux/wiki\" target=\"_blank\" rel=\"noreferrer\"\u003eTmux\u003c/a\u003e as a shared terminal state. This allows me to hand off a live session to my \u003ca href=\"https://clawd.bot/\" target=\"_blank\" rel=\"noreferrer\"\u003eClawdbot\u003c/a\u003e agent and, conversely, take over a session that the agent started. It also provides a mechanism to optionally switch between different account tokens (such as a work account) on the fly.\u003c/p\u003e","title":"Tag-Teaming Claude Code with an AI Agent via Tmux"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/tmux/","section":"Tags","summary":"","title":"Tmux"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/workflow/","section":"Tags","summary":"","title":"Workflow"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/ai/","section":"Tags","summary":"","title":"AI"},{"content":"I wanted to set up a \u0026ldquo;Family Agent\u0026rdquo; in Clawdbot so my family could interact with tools like stock analysis and summarization via WhatsApp. However, I needed to ensure this agent was completely isolated from my personal credentials and host system. Here is how I configured a sandboxed environment and deployed cross-compiled Go skills to solve this.\nCustomizing the Sandbox Image #Because some skills have specific runtime requirements—like the summarize skill needing Node.js 20+ to support newer regular expression flags—I created a custom Docker image. Using a default image with Node.js v18 resulted in a SyntaxError when the tool\u0026rsquo;s dependencies tried to load, so \u0026ldquo;baking in\u0026rdquo; the correct runtime was the first step.\nThe Dockerfile #I used a node:20-slim base to ensure all modern Node dependencies were supported:\nFROM node:20-slim # Install system dependencies RUN apt-get update \u0026amp;\u0026amp; apt-get install -y \\ curl \\ ca-certificates \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* WORKDIR /app Building the image is a one-time task:\ndocker build -t [YOUR_DOCKER_IMAGE]:1.0 . Cross-Compiling Go Binaries for Multi-Platform Support #To keep the agent high-performance, I wrote my custom skills (like stock-analysis) in Go. The beauty of Go is the ability to test locally on my M1 Max (darwin/arm64) and then cross-compile for the sandboxed Linux environment.\nBy producing a single binary for each platform and placing them in the dist/ folder of the skill, the agent can run the correct version regardless of the environment.\n# Build for macOS (Local Testing) GOOS=darwin GOARCH=arm64 go build -o dist/stock-analysis main.go # Build for Linux (Sandbox Deployment) GOOS=linux GOARCH=arm64 go build -o dist/stock-analysis-linux main.go Bridging the LLM and Code with SKILL.md #Clawdbot uses a SKILL.md file to discover these binaries and understand how to use them. This file acts as the bridge between the LLM’s natural language and the Go code. For the stock analysis tool, I defined mandatory rules to ensure the agent returns the raw stdout verbatim, which is critical for trading data fidelity.\n### Command # macOS / Darwin stock-analysis \u0026lt;TICKER\u0026gt; # Linux / Sandbox stock-analysis-linux \u0026lt;TICKER\u0026gt; Configuring the Agent and Docker Sandbox #With the image built and skills compiled, I defined the family agent in clawdbot.json. Setting the sandbox mode to all forces every tool execution into the Docker container.\nCrucially, because skills like summarize and stock-analysis need to reach out to external APIs and websites, I had to explicitly grant the sandbox internet access by setting the Docker network to bridge mode.\nThe Agent JSON Structure #The env block and sandbox settings live directly within the agent\u0026rsquo;s definition. Here is the full structure for the family agent:\n{ \u0026#34;id\u0026#34;: \u0026#34;family\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;family\u0026#34;, \u0026#34;env\u0026#34;: { \u0026#34;ANTHROPIC_API_KEY\u0026#34;: \u0026#34;{{auth:[YOUR_ANTHROPIC_PROFILE]}}\u0026#34;, \u0026#34;GEMINI_API_KEY\u0026#34;: \u0026#34;{{auth:[YOUR_GEMINI_PROFILE]}}\u0026#34; }, \u0026#34;workspace\u0026#34;: \u0026#34;[WORKSPACE_PATH]\u0026#34;, \u0026#34;sandbox\u0026#34;: { \u0026#34;mode\u0026#34;: \u0026#34;all\u0026#34;, \u0026#34;workspaceAccess\u0026#34;: \u0026#34;rw\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;agent\u0026#34;, \u0026#34;docker\u0026#34;: { \u0026#34;image\u0026#34;: \u0026#34;[YOUR_DOCKER_IMAGE]:1.0\u0026#34;, \u0026#34;network\u0026#34;: \u0026#34;bridge\u0026#34; } }, \u0026#34;tools\u0026#34;: { \u0026#34;sandbox\u0026#34;: { \u0026#34;tools\u0026#34;: { \u0026#34;allow\u0026#34;: [\u0026#34;exec\u0026#34;, \u0026#34;bash\u0026#34;, \u0026#34;read\u0026#34;, \u0026#34;write\u0026#34;, \u0026#34;summarize\u0026#34;, \u0026#34;stock-analysis\u0026#34;] } } } } I then bound this agent to a specific WhatsApp group ID so it only responds to family requests:\n\u0026#34;bindings\u0026#34;: [ { \u0026#34;agentId\u0026#34;: \u0026#34;family\u0026#34;, \u0026#34;match\u0026#34;: { \u0026#34;channel\u0026#34;: \u0026#34;whatsapp\u0026#34;, \u0026#34;peer\u0026#34;: { \u0026#34;kind\u0026#34;: \u0026#34;group\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;[YOUR_GROUP_ID]@g.us\u0026#34; } } } ] Lessons Learned #1. Secure Credential Injection #A key security feature of the sandbox is that it starts with a clean slate. By checking the sandbox logs, I could see that tools were failing because they lacked API keys. To fix this, I used explicit environment mapping in the JSON config.\nYou must map the specific environment variables that your skills expect (like GEMINI_API_KEY or ANTHROPIC_API_KEY) to your secure Clawdbot authentication profiles inside the env block shown in the configuration section above.\nThis ensures the agent is \u0026ldquo;least privileged\u0026rdquo;—it only has the specific tokens it needs to run its assigned skills.\nPro-Tip: Refreshing the Sandbox #Clawdbot creates the Docker container for the agent only one time. It persists across restarts for speed. If you need to force a clean slate or pick up changes in your custom image, simply delete the running container:\ndocker rm -f [CONTAINER_ID] Clawdbot will automatically recreate the container from the image on the next request.\nWrapping Up #By using Docker for isolation, enabling bridge networking for internet access, and cross-compiling Go binaries for both macOS and Linux, I’ve created a setup that is both high-performance and secure. This configuration allows my family to benefit from agentic workflows while maintaining strict control over credential access and runtime environments.\n","date":"Jan 19, 2026","permalink":"http://localhost:1313/blog/deploying-sandboxed-family-agent-clawdbot/","section":"Blogs","summary":"\u003cp\u003eI wanted to set up a \u0026ldquo;Family Agent\u0026rdquo; in \u003ca href=\"https://clawd.bot/\" target=\"_blank\" rel=\"noreferrer\"\u003eClawdbot\u003c/a\u003e so my family could interact with tools like stock analysis and summarization via WhatsApp. However, I needed to ensure this agent was completely isolated from my personal credentials and host system. Here is how I configured a sandboxed environment and deployed cross-compiled \u003ca href=\"https://go.dev/\" target=\"_blank\" rel=\"noreferrer\"\u003eGo\u003c/a\u003e skills to solve this.\u003c/p\u003e","title":"Deploying a Sandboxed Family Agent with Cross-Compiled Go Skills in Clawdbot"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/docker/","section":"Tags","summary":"","title":"Docker"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/go/","section":"Tags","summary":"","title":"Go"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/stock-analysis/","section":"Tags","summary":"","title":"Stock Analysis"},{"content":"After upgrading to macOS Sequoia (15.0), my QFX files would not open correctly in Banktivity. Banktivity would not show as an option in Open With in the File Info panel. I ended up having to use lsregister utility to fix the association manually.\nThe problem turned out to be that macOS Launch Services db had references to older versions of Banktivity that were no longer installed. I had version 9 installed, but it had assoications registered to version 7, 8 and 9. I also found that my iOS device had both Banktivity 7 and Banktivity 9 installed. I belive this was causing conflicts on macOS because of iCloud File Sync. I found out the associated by running the below command.\n/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/Support/lsregister -dump | grep -i \u0026#34;path:.*banktivity\u0026#34; Output:\npath: /Users/\\*\\*\\*/Library/Daemon Containers/\\*\\*\\*/Data/Library/Caches/Placeholders-v2.noindex/com.iggsoftware.banktivity4-mobile-7.5.2/Banktivity 7.app (0x52f8) path: /Users/\\*\\*\\*/Library/Daemon Containers/\\*\\*\\*/Data/Library/Caches/Placeholders-v2.noindex/com.iggsoftware.banktivity-9.5.3/Banktivity.app (0x53a4) path: /Applications/Banktivity.app (0x6568) I unregistering all registered listed paths using the below command for each path.\n/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/Support/lsregister -u \u0026#34;/Applications/Banktivity.app\u0026#34; Once I unregistered all. I registered the only valid path.\n/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/Support/lsregister -R -f -v /Applications/Banktivity.app This fixed my QFX file associations for Banktivity.\nPS: using the force cleanup of all file associations on Sequoia using the below command will fix the issue until a reboot. But it also breaks System Settings. None of the panels in System Settings load after running the below command.\n/System/Library/Frameworks/CoreServices.framework/Frameworks/LaunchServices.framework/Support/lsregister -kill -r -domain local -domain system -domain user So I recommend not using this command.\n","date":"Oct 25, 2024","permalink":"http://localhost:1313/blog/fixing-file-associations-on-macos-sequoia/","section":"Blogs","summary":"\u003cp\u003eAfter upgrading to macOS Sequoia (15.0), my QFX files would not open correctly in \u003cem\u003e\u003ca href=\"https://www.banktivity.com\" target=\"_blank\" rel=\"noreferrer\"\u003eBanktivity\u003c/a\u003e\u003c/em\u003e. Banktivity would not show as an option in \u003cem\u003eOpen With\u003c/em\u003e in the File Info panel. I ended up having to use \u003cem\u003elsregister\u003c/em\u003e utility to fix the association manually.\u003c/p\u003e","title":"Fixing File Associations on macOS Sequoia"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/sequoia/","section":"Tags","summary":"","title":"Sequoia"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/dcoker/","section":"Tags","summary":"","title":"Dcoker"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/portainer/","section":"Tags","summary":"","title":"Portainer"},{"content":"I run a docker instance under Ubuntu server on my local network. This is how I upgrade portainer to the latest version.\nConnect to the Ubuntu server via SSH and run the below commands.\n# Stop portainer sudo docker stop portainer # Remove existing container sudo docker rm portainer # Pull the latest portainer-ce image sudo docker pull portainer/portainer-ce:latest # Create and start portainer using the latest image. sudo docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest This will upgrade portainer to the latest version. It should again be accessible at http://\u0026lt;\u0026lt;server\u0026gt;\u0026gt;:9000.\n","date":"Feb 19, 2023","permalink":"http://localhost:1313/blog/upgrading-portainer-ce-on-docker/","section":"Blogs","summary":"\u003cp\u003eI run a docker instance under Ubuntu server on my local network. This is how I upgrade portainer to the latest version.\u003c/p\u003e","title":"Upgrading Portainer Community Edition on Docker"},{"content":"","date":null,"permalink":"http://localhost:1313/categories/home-automation/","section":"Categories","summary":"","title":"Home Automation"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/home-automation/","section":"Tags","summary":"","title":"Home Automation"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/homekit/","section":"Tags","summary":"","title":"HomeKit"},{"content":"The Foscam Floodlight Camera is competitively prized and has decent features including option to record 24/7 video locally to a micro sdcard without the need for a cloud subscription. It however does not support integration with HomeKit my preferred home automation platform. Here is how I setup the floodlight in HomeKit.\nDownload and install the Foscam VMS app from the Mac App Store. Signup and Signin to the Foscam Account.\nWe will also need the Foscam iOS app.\nWe need both macOS and iOS apps because unfortunately certain settings are only available in the macOS app where others are only available in the iOS app.\nFoscam VMS (macOS) App Settings #Once the camera is setup and available in the Foscam VMS app, goto the the camera settings by clicking the settings icon next to the camera name.\nOpen Camera Settings Set the settings like so:\nBasic Settings # Set Device name and Device time. Disable Voice prompt. Video Settings # Set Video encode settings like below. Set both the Main stream and Sub stream settings like the one in the screenshot. You may choose to use QHD stream type if you prefer 2K resolution, however I found the response time to be slower in HomeKit with that. Video Encode Settings Set On screen display -\u0026gt; Display timestamp to Yes. Set Privacy zone -\u0026gt; Privacy zone to Yes. We are going to be using the Privacy zone to make the On screen time display readable. You can drag the privacy zone around the time area, but I found the drag operation to be very hard due to responsiveness issues. We will instead use Foscam CGI Command to set the privacy zone later in the section.\nI found the default colors to be oversaturated so I tweaked the Color adjustment like below. Color Adjustment Settings Detector Settings # I found the camera\u0026rsquo;s onboard motion detector to be too conservative for my liking so I disabled the Motion Detection \u0026amp; Sound Detection under the Detector settings. The only setting turned on is the PIR Detection. PIR Detection Settings Record Settings # Enable SD card option under Record. Under Schedule Recording I enabled 24/7 Recording including Audio by tapping the All area in the Schedule table. Record Schedule Settings Save and close the Camera Settings window.\nMaking the Onscreen Time Readable #By default the onscreen time has not background and so it is overlayed directly on the video. This makes the time in the video hard to read. In order to fix this we use the Privacy zone and setup a rectangle around the time. This way it will alway have a black background behind the time, improving readablity.\nRun the below command adjusting values for the camera-ip, camera-user-name, and camera-user-password to setup the privacy rectangle behind time.\ncurl \u0026#34;http://\u0026lt;\u0026lt;camera-ip\u0026gt;\u0026gt;:88/cgi-bin/CGIProxy.fcgi?cmd=setOsdMaskArea\u0026amp;x1_0=20\u0026amp;y1_0=90\u0026amp;x2_0=2080\u0026amp;y2_0=450\u0026amp;usr=\u0026lt;\u0026lt;camera-user-name\u0026gt;\u0026gt;\u0026amp;pwd=\u0026lt;\u0026lt;camera-user-password\u0026gt;\u0026gt;\u0026#34; Readable Time Foscam (iOS) App Settings # Load the Camera Settings by tapping the \u0026hellip; button and tapping Settings. Select Advanced Settings. Automatic firmware updates are on by default. Disable them under Smart Update. Enable Onvif Under NVR Connection Enable NVR Model When NVR and ONVIF are enabled, the stream switches to H264 which is required for HomeKit integration. Without that the default stream format is H265 which is incompatible with HomeKit.\nOnvif Settings NVR Connection Settings Adding the camera to Scrypted #We will be using the excellent Scrypted platform to access this camera from HomeKit and also enable HomeKit Secure Video. I have Scrypted running in a Docker container on a Ubuntu server.\nUnder Scrypted install the below plugins.\nHomeKit - For exposing camera to HomeKit RTSP Camera Plugin - For connecting to Foscam floodlight camera via RTSP stream. Open CV Motion Detection - To expose custom motion detection sensing via OpenCV so Home Hub can process motion and record clips to HomeKit Secure Video. Dummy Switch Plugin - To control the floodlight via HomeKit. RTSP Camera Plugin Setup # Navigate to RTSP Camera Plugin page and click Add Device. Enter a name for your camera and click Create Under the newly loaded device page in the General tab, click the Add button so you have a place to enter two RTSP Stream URL. Enter the information for Username - The camera username Password - The camera password RTSP Stream URL - http://\u0026lt;\u0026lt;camera-ip-address\u0026gt;\u0026gt;:88/videoMain RTSP Stream URL - http://\u0026lt;\u0026lt;camera-ip-address\u0026gt;\u0026gt;:88/videoSub Click Save RTSP Stream URL and the Save button. Refresh the Page. This should load the snapshot of the camera and also show additional tabs. Switch to the Stream Management tab and change the Low Resolution Stream value to Stream 2. Switch to the Integrations and Extensions tab and check OpenCV Motion Detection and HomeKit. Refresh the page. The integrations should look like the below screenshot. Integrations and Extensions Switch to the OpenCV Motion Detection tab and set the settings as you wish to tweak. For my setup I only changed the Motion Area to 1000, Motion Threshold to 15, and Frame Analysis Interval to 500. OpenCV Motion Detection Switch to the HomeKit Pairing tab and make sure the Standalone Accessory Mode is checked. You may now add the camera to HomeKit. The QR Code to pair with HomeKit will be available under the HomeKit tab of the camera under Scrypted. Operating the Floodlight # Install the Foscam Floodlight Plugin from scrypted plugins. Select Add Device and enter a name for the Floodlight. On the Device page under General Settings set the Foscam IP to the device camera ip. Note the default port for the Camera is 88. Set the camera Username and Password and hit Save. Enable HomeKit integration, and pair with HomeKit. The device will now let you to turn the floodlight on/off and set the brightness. I also blocked the camera ips from accessing the internet except the NTP port via my firewall. The cameras connect locally to my Home Hub (Apple TV) and then are available to HomeKit everywhere through that. So that is an additional level of privacy I enjoy. Overall this setup is working very well and HomeKit recognizes People/Pets/Vehicles and Packages pretty well and quickly.\n","date":"Nov 13, 2022","permalink":"http://localhost:1313/blog/set-up-foscam-floodlight-camera-in-homekit/","section":"Blogs","summary":"\u003cp\u003eThe \u003ca href=\"https://www.amazon.com/Foscam-Floodlight-Detection-Brightness-FLC/dp/B095S3HVL4\" target=\"_blank\" rel=\"noreferrer\"\u003eFoscam Floodlight Camera\u003c/a\u003e is competitively prized and has decent features including option to record 24/7 video locally to a micro sdcard without the need for a cloud subscription. It however does not support integration with HomeKit my preferred home automation platform. Here is how I setup the floodlight in HomeKit.\u003c/p\u003e","title":"Set up Foscam Floodlight Camera in HomeKit"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/artificial-intelligence/","section":"Tags","summary":"","title":"Artificial Intelligence"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/deep-learning/","section":"Tags","summary":"","title":"Deep Learning"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/keras/","section":"Tags","summary":"","title":"Keras"},{"content":"","date":null,"permalink":"http://localhost:1313/categories/machine-learning/","section":"Categories","summary":"","title":"Machine Learning"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/machine-learning/","section":"Tags","summary":"","title":"Machine Learning"},{"content":"I am currently reading Deep Learning with TensorFlow and Keras to get started with Machine Learning/Deep Learning. Here is how I setup a local Keras/Tensorflow 2.0 environment on my M1 Max MacBook Pro running macOS 12.6.\nInstall miniconda.\nbrew install --cask miniconda I use zsh with iTerm2 as my terminal so I need to initialize conda with the following command.\nconda init zsh This will make it so everytime iTerm2 is opened, the conda base environment will be activated. I prefer to activate my environment manually, so I did the below to deactivate the base environment on launch of iTerm2.\nIn ~/.zshrc add the following section after the # \u0026lt;\u0026lt;\u0026lt; conda initialize \u0026lt;\u0026lt;\u0026lt; line.\n# Deactivate base conda environment. You can activate an environment using conda activate \u0026lt;\u0026lt;environment-name\u0026gt;\u0026gt; conda deactivate We now create an environment named tensorflow where we could run our ML/DL Keras training.\nconda create -n tensorflow python=3.9 We then switch to the tensorflow environment and install dependencies.\n# Activate tensorflow environment conda activate tensorflow # Install apple tensorflow dependencies conda install -c apple tensorflow-deps # Install tensorflow macos python -m pip install tensorflow-macos # Install tensorflow metal plugin python -m pip install tensorflow-metal # Install tensorflow readymade datasets python -m pip install tensorflow-datasets # Install libjpeg (needed by mathplotlib) brew install libjpeg # Install mathplotlib and jupyterlab conda install -y matplotlib jupyterlab This may not be necessary for future installs. But I ran into an error with numpy when trying to run my notebook code.\nmodule compiled against API version 0x10 but this version of numpy is 0xf\nTo correct this I had to run this command in my tensorflow environment.\npython -m pip install numpy --upgrade Another warning I ran into.\nTqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html from .autonotebook import tqdm as notebook_tqdm\nTo resolve I ran the below in my tensorflow environment.\npython -m pip install ipywidgets widgetsnbextension pandas-profiling You may now run jupyter notebook command from the tensorflow environment to start the jupyter notebook environment from the command line. I however prefer using Visual Studio Code and start an environment under vscode as documented below.\nInstall the Jupyter extension under vscode. Load the Command Pallet using (Cmd+Shift+P) and select Jupyter: Select Interpreter to Start Jupyter Server and then select Python 3.9.13 ('tensorflow') or whatever environment you want to use. Load the Command Pallet using (Cmd+Shift+P) and select Create: New Jupyter Notebook You may now run all the Jupyter notebook in vscode. When run the code cell, vscode will start the jupyter server if it is not already started in the selected environment. Code #import tensorflow as tf print(\u0026#34;TensorFlow has access to the following devices:\u0026#34;) for device in tf.config.list_physical_devices(): print(f\u0026#34;* {device}\u0026#34;) Output #TensorFlow has access to the following devices: * PhysicalDevice(name=\u0026#39;/physical_device:CPU:0\u0026#39;, device_type=\u0026#39;CPU\u0026#39;) * PhysicalDevice(name=\u0026#39;/physical_device:GPU:0\u0026#39;, device_type=\u0026#39;GPU\u0026#39;) ","date":"Oct 21, 2022","permalink":"http://localhost:1313/blog/setting-up-keras-tensorflow2-on-m1-mac/","section":"Blogs","summary":"\u003cp\u003eI am currently reading \u003ca href=\"https://www.amazon.com/gp/product/B0B18D695W\" target=\"_blank\" rel=\"noreferrer\"\u003eDeep Learning with TensorFlow and Keras\u003c/a\u003e to get started with Machine Learning/Deep Learning. Here is how I setup a local \u003cem\u003eKeras/Tensorflow 2.0\u003c/em\u003e environment on my \u003cem\u003eM1 Max MacBook Pro\u003c/em\u003e running \u003cem\u003emacOS 12.6\u003c/em\u003e.\u003c/p\u003e","title":"Setting up Keras Tensorflow2 on M1 Mac"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/tensorflow/","section":"Tags","summary":"","title":"TensorFlow"},{"content":"Visual Studio Code is quite capable has become my editor of choice on macOS. Here is how to set it as the default text editor instead of Text Edit.\nInstall duti.\nbrew install duti Set Visual Studio Code as the default editor for all text files and public files by running the below commands using duti.\n# Mark vscode as default editor for all text files duti -s com.microsoft.VSCode public.plain-text all # Some files without extensions are considered public.data and not public.text. Set those to open in vscode as well duti -s com.microsoft.VSCode public.data all The changes should take effect right away and no reboot or relaunch of Finder should be needed.\n","date":"Mar 23, 2021","permalink":"http://localhost:1313/blog/setting-vscode-as-default-text-editor-on-macos/","section":"Blogs","summary":"\u003cp\u003e\u003ca href=\"https://code.visualstudio.com\" target=\"_blank\" rel=\"noreferrer\"\u003eVisual Studio Code\u003c/a\u003e is quite capable has become my editor of choice on macOS. Here is how to set it as the default text editor instead of \u003cem\u003eText Edit\u003c/em\u003e.\u003c/p\u003e","title":"Setting Visual Studio Code as default text editor on macOS"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/visual-studio-code/","section":"Tags","summary":"","title":"Visual Studio Code"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/vscode/","section":"Tags","summary":"","title":"Vscode"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/active-directory/","section":"Tags","summary":"","title":"Active Directory"},{"content":"Macs connected to Active Directory routinely need to update passwords. When working remote, Active Directory password change is not exactly easy. Here are the steps I follow to update my Active Directory password and keep my local mac password in sync.\nConnect to corporate VPN so that Active Directory is reachable over VPN. Open Terminal and run the following command.\nkpasswd myusername@FULLADDOMAIN.COM myusername@FULLADDOMAIN.COM\u0026#39;s Password: New password for myusername@FULLADDOMAIN.COM: Verify password - New password for myusername@FULLADDOMAIN.COM: Success Once password change is confirmed, run the following to force sync the updated password to keychain.\ndsconfigad -passinterval 0 Wait about a minute, log out and log back in. You should be logging in with the new password. If login still requires the old password the password sync with active directory did not happen yet. Log back in with the old password, connect to VPN (You will need to use your new password when connecting to VPN) and run the dsconfigad -passinterval 0 command and wait a mintue or so before trying to log out/login.\nThe process once finished will make sure your local keychain password and AD passwords are in sync.\n","date":"Jan 02, 2021","permalink":"http://localhost:1313/blog/macos-and-active-directory-passwords/","section":"Blogs","summary":"\u003cp\u003eMacs connected to Active Directory routinely need to update passwords. When working remote, Active Directory password change is not exactly easy. Here are the steps I follow to update my Active Directory password and keep my local mac password in sync.\u003c/p\u003e","title":"macOS and Active Directory Passwords"},{"content":"I needed to compile an arm64 binary to run on the UniFi Dream Machine Pro. This is how I used docker to setup cross compilation tools and compile the binary on macOS.\nGet and install Docker Desktop is not already installed. Once installed we can use DockCross to setup an cross compile tool chain we want. Here is an example of how I setup the linux-arm64 toolchain.\nmkdir -p ~/Documents/dockcross cd ~/Documents/dockcross docker run --rm dockcross/linux-arm64 \u0026gt; ./dockcross-linux-arm64 chmod +x ./dockcross-linux-arm64 This will setup a linux-arm64 cross compiler. To compile files using this compiler you have to place the files in the same directory as the binary. Here is an exaple of how to compile.\n./dockcross-linux-arm64 bash \\ -c \u0026#39;$CC -s -O3 main.c -o ./udp-broadcast-relay-redux\u0026#39; Examining the compiled binary with file command should display ARM aarch64 architecture.\nfile udp-broadcast-relay-redux udp-broadcast-relay-redux: ELF 64-bit LSB executable, ARM aarch64, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux-aarch64.so.1, for GNU/Linux 4.10.8, stripped Note: Using $CC is important. If you use gcc directly it will compile using x86_64 version.\n","date":"Dec 23, 2020","permalink":"http://localhost:1313/blog/cross-compiling-on-macos-via-docker/","section":"Blogs","summary":"\u003cp\u003eI needed to compile an arm64 binary to run on the \u003ca href=\"https://store.ui.com/collections/unifi-network-routing-switching/products/udm-pro\" target=\"_blank\" rel=\"noreferrer\"\u003eUniFi Dream Machine Pro\u003c/a\u003e. This is how I used docker to setup cross compilation tools and compile the binary on macOS.\u003c/p\u003e","title":"Cross Compiling on macOS via Docker"},{"content":"","date":null,"permalink":"http://localhost:1313/categories/networking/","section":"Categories","summary":"","title":"Networking"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/ubiquiti/","section":"Tags","summary":"","title":"Ubiquiti"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/android/","section":"Tags","summary":"","title":"Android"},{"content":"While reviewing an Android project I discovered it was using Dagger 2 framework. Dagger 2 is a dependency injection framework for Android that is developed by Google. I wanted a quick overview of frameworks major features.\nI found the below video series by codinginflow.com extermely well done.\nWatch on codinginflow.com\nWatch on YouTube\n\u0026ndash; Florian (codinginflow.com)\nHe also has a lot of other Android development related series available on his site.\n","date":"May 22, 2020","permalink":"http://localhost:1313/blog/dagger-2-beginner-tutorial/","section":"Blogs","summary":"\u003cp\u003eWhile reviewing an Android project I discovered it was using \u003ca href=\"https://dagger.dev\" target=\"_blank\" rel=\"noreferrer\"\u003eDagger 2\u003c/a\u003e framework. Dagger 2 is a dependency injection framework for Android that is developed by Google. I wanted a quick overview of frameworks major features.\u003c/p\u003e","title":"Dagger 2 Beginner Tutorial"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/catalina/","section":"Tags","summary":"","title":"Catalina"},{"content":"My work has multiple domains (corp.network and lab.network) that the nameservers resolve. When in the office the resolution works perfectly. However while conncting over VPN via Tunnelblick the resolution to lab.network was failing.\nI could go into my System Preferences-\u0026gt;Network Settings and modify my wifi interface settings to enter a new DNS value for those specific domains. But that felt tedious. Instead I used the below method to specify custom DNS resolver settings for my work domains.\nUnder /etc/resolver create a file with a name of your choice. I chose corp.netowrk just for clarity.\nHere is an example of what the contents could be.\ndomain corp.network nameserver 10.0.0.1 nameserver 10.0.0.2 I could create another file for the lab network with a different dns server.\ndomain lab.network nameserver 10.0.1.1 The above would make it so any lookup to xxx.corp.network would use the specified nameserver at 10.0.0.1 and 10.0.0.2. If I try to access devserver.lab.network it would ask the nameserver at 10.0.1.1 for its IP.\nYou could take it a step further and provide backup lookup settings. For example you may have a server located at demo.corp.com that resolves different IPs based on if you are connected to VPN or not. So demo.corp.com should be resolved via VPN nameservers when you are connected to VPN, but via ISP name servers when not connected to VPN. To achive this you could create two files under /etc/resolver like so.\ndomain corp.com nameserver 10.0.0.1 nameserver 10.0.0.2 search_order 1 timeout 5 domain corp.com nameserver 1.1.1.1 nameserver 1.0.0.1 search_order 2 The above two files make it so the macOS DNS resolver will first try to use the VPN domains for resolution. If we dont get a response withing 5 seconds, it will fallback to the second file and use Cloudflare DNS to do an internet lookup of the IP address.\n","date":"May 22, 2020","permalink":"http://localhost:1313/blog/domain-specific-dns-servers-on-macos/","section":"Blogs","summary":"\u003cp\u003eMy work has multiple domains (\u003ccode\u003ecorp.network\u003c/code\u003e and \u003ccode\u003elab.network\u003c/code\u003e) that the nameservers resolve. When in the office the resolution works perfectly. However while conncting over VPN via Tunnelblick the resolution to lab.network was failing.\u003c/p\u003e","title":"Domain Specific DNS Servers on macOS"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/vpn/","section":"Tags","summary":"","title":"VPN"},{"content":"I needed to connect to a corporate VPN that used WatchGuard. The IT provided Mobile VPN with SSL Client software did not work reliably on macOS Catalina. It sometimes show connected but unable to access remote vpn resources.\nI discovered that the WatchGuard VPN internally is an OpenVPN server. I use Tunnelblick for my personal OpenVPN connections and that has worked reliably on macOS Catalina. So if I just had the connection ovpn config file I could use Tunnelblick for my VPN connections.\nWatchGuard has a detailed support document that walks the user through downloading their software to use for VPN connection at https://www.watchguard.com/help/docs/fireware/12/en-US/Content/en-US/mvpn/ssl/mvpn_ssl_client-install_c.html.\nTurns out that page also provides an option to download the ovpn config that can be used with Tunnelblick.\nAcquiring the OVPN config # Browse to https://\u0026lt;yourvpnserverip:port\u0026gt;/sslvpn.html. You will be greeted with a login page. WatchGuard - Login Page Login using your corporate credentials. You will be offered a download page. WatchGuard - Download Page Select the Download option under Mobile VPN with SSL client profile. This will offer a client.ovpn file that you can import into Tunnelblick for connection to your corporate network. The page offer options to download the Mobile VPN with SSL Client software for Mac and Windows as well if you want those.\n","date":"Apr 26, 2020","permalink":"http://localhost:1313/blog/using-tunnelblick-to-connect-to-watchguard-vpn/","section":"Blogs","summary":"\u003cp\u003eI needed to connect to a corporate VPN that used \u003ca href=\"https://www.watchguard.com\" target=\"_blank\" rel=\"noreferrer\"\u003eWatchGuard\u003c/a\u003e. The IT provided \u003cem\u003eMobile VPN with SSL Client\u003c/em\u003e software did not work reliably on macOS Catalina. It sometimes show connected but unable to access remote vpn resources.\u003c/p\u003e","title":"Using Tunnelblick to Connect to WatchGuard VPN"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/documentation/","section":"Tags","summary":"","title":"Documentation"},{"content":"","date":null,"permalink":"http://localhost:1313/categories/interesting-tools/","section":"Categories","summary":"","title":"Interesting Tools"},{"content":"I often need to document a flow chart for new features I am planning to implement. Usually generating flow chart needed me to go to an application that would let me draw rectangles, text, etc. Today I learned about mermaid-js which allows one to use Markdown like syntax to generte various diagrams including flow charts.\nThere is a live editor available at https://mermaidjs.github.io/mermaid-live-editor/ that allows you to to enter Markdown like text and generate a PNG/SVG output that you can download and embed in your documentation.\ngraph TD A[Christmas] --\u0026gt;|Get money| B(Go shopping) B --\u0026gt; C{Let me think} C --\u0026gt;|One| D[Laptop] C --\u0026gt;|Two| E[iPhone] C --\u0026gt;|Three| F[fa:fa-car Car] The embedded code block above would generate a flow chart image like the one below.\nmermaid-js supports generating\nFlow Chart Sequence Diagram Class Diagram State Diagram Gantt Chart Pie Chart ER Diagram Documentation is available at https://mermaid-js.github.io/mermaid.\n","date":"Apr 24, 2020","permalink":"http://localhost:1313/blog/using-mermaid-js-to-generate-flow-charts/","section":"Blogs","summary":"\u003cp\u003eI often need to document a flow chart for new features I am planning to implement. Usually generating flow chart needed me to go to an application that would let me draw rectangles, text, etc. Today I learned about \u003ca href=\"https://github.com/mermaid-js/mermaid\" title=\"mermaid-js GitHub Page\" target=\"_blank\" rel=\"noreferrer\"\u003emermaid-js\u003c/a\u003e which allows one to use Markdown like syntax to generte various diagrams including flow charts.\u003c/p\u003e","title":"Using mermaid-js to generate Flow Charts"},{"content":"","date":null,"permalink":"http://localhost:1313/categories/web/","section":"Categories","summary":"","title":"Web"},{"content":"For a while, I have been considering building a website to document things I learn. This year I decided to stop procsanating and get started with it.\nIntroducing patelhiren.com in all its glory. \u0026#x1f389;\nGoals #For this site I had a few basic goals in mind.\nIt should serve as a log to help me remember and reivew how I did things. I hope that others may find it helpful as well. The website should be fast and light. Should not be overburdened with Javascript. Should be able to host website with a simple webserver. No server side software should be necessary. Allowed me to keep my content in a standard text + image format for easy parsing even when not viewing via a browser. I did not want my content to be stored in binary formats in a database. I want it to be stored in plain text files on the filesystem. Support code syntax highlighting. Support SSL encryption on the website. Support emoji. The above goals meant I was going to be building a Static Site using one of the many Static Site Generator Tools\nTools #After deciding I wanted a static site, I researched the various Static Site Generator Tools and settled on Hugo as my choice.\nHugo written in Go, is highly reviewed and praised for its speed of site generation. It supports macOS (my primary OS of choice), Windows, Linux, OpenBSD and FreeBSD. It has a very well documented site and looks to have an active community developing and supporting it. It allows me to create my content in Markdown syntax thus allowing me to keep it in plain text on the filesystem. It also supports code syntax highlighting and emoji \u0026#x1f44c;. You can check details of Hugo\u0026rsquo;s Makrdown support at markdownguide.org\nHugo supports a variety of Themes. I settled on Notepadium because it provided most of what I wanted out of box. I plan to customize it a bit to my liking as I learn more.\nHosting #For hosting I decided to use GitHub Pages. GitHub Pages is free, supports SSL and provides automatic CDN for serving fast webpages closer to your user. It also had the added benefit of having my generated site auotmatically have commit history and remote backup.\nInstalling Hugo and Building your site #I use macOS as my primary OS so these steps are for for the Mac. However the steps should be very similar if you are using any other supported OS. Homebrew and git 1 is expected to be installed before you follow the rest of the steps.\nInstall Hugo\nbrew install hugo To verify the install run\nhugo version Create your new site\nhugo new site patelhiren.com Add the Notepadium Theme\ncd patelhiren.com git init git submodule add https://github.com/cntrump/hugo-notepadium themes/notepadium Activate the theme for your site by adding it to the config.toml\necho \u0026#39;theme = \u0026#34;notepadium\u0026#34;\u0026#39; \u0026gt;\u0026gt; config.toml Create a new post 2\nhugo new blog/my-first-post/index.md You can find your content under content folder. You can open the newly created index.md file in any Markdown editor of choice 3 and edit and save your content. Here is an example post to suggest what\u0026rsquo;s possible.\n--- title: \u0026#34;My First Post\u0026#34; description: \u0026#34;This is my first post in Hugo. This shows up in Google search.\u0026#34; date: 2020-04-18T16:08:20-04:00 draft: true tags: [ \u0026#34;Tag 1\u0026#34;, \u0026#34;Tag 2\u0026#34; ] categories: [ \u0026#34;Category 1\u0026#34;, \u0026#34;Category 2\u0026#34; ] --- Hello everyone welcome to you website. \u0026lt;!--more--\u0026gt; This is the extended content of my first post. Once you save your content you can test it locally by activating Hugo local web server.\nhugo server -D You can navigate to your local site at http://localhost:1313/.\nEdit you config.toml to configure the rest of your site settings. Here is mine.\nbaseURL = \u0026#34;https://patelhiren.com/\u0026#34; languageCode = \u0026#34;en-us\u0026#34; title = \u0026#34;Hiren Patel\u0026#34; theme = \u0026#34;notepadium\u0026#34; copyright = \u0026#34;©2020 Hiren Patel.\u0026#34; enableEmoji = true enableRobotsTXT = true [markup.highlight] codeFences = true noClasses = false linenos = true [markup.goldmark.renderer] unsafe = true # enable raw HTML in Markdown [params] style = \u0026#34;auto\u0026#34; # default: auto. light: light theme, dark: dark theme, auto: based on system. dateFormat = \u0026#34;Jan 02, 2006\u0026#34; # if unset, default is \u0026#34;2006-01-02\u0026#34; readingTime = false # show reading time after article date logo = \u0026#34;patelhiren-logo.png\u0026#34; slogan = \u0026#34;Documenting things as I learn.\u0026#34; [params.assets] css = [\u0026#34;css/fonts.css\u0026#34;, \u0026#34;css/light.css\u0026#34;, \u0026#34;css/dark.css\u0026#34;] [params.comments] enable = false # En/Disable comments globally, default: false. You can always enable comments on per page. [params.share] enable = false # En/Disable share globally, default: false. You can always enable share on per page. addThisId = \u0026#34;\u0026#34; inlineToolId = \u0026#34;\u0026#34; [params.math] enable = false # load math globally, default: false. You can always enable math on per page. use = \u0026#34;katex\u0026#34; # builtin: \u0026#34;katex\u0026#34;, \u0026#34;mathjax\u0026#34;. default: \u0026#34;katex\u0026#34; [params.syntax] use = \u0026#34;none\u0026#34; # builtin: \u0026#34;prismjs\u0026#34;, \u0026#34;hljs\u0026#34;. \u0026#34;none\u0026#34; means Chroma theme = \u0026#34;xcode\u0026#34; darkTheme = \u0026#34;xcode-dark\u0026#34; [params.nav] showCategories = true # /categories/ showTags = true # /tags/ To build your static site run:\nhugo -D The output will be saved under ./public/ directory. You may copy the contents of this folder to any webserver and your website will be servered.\nHosting your site on GitHub Pages # Create a repository to hold your Hugo content and source files on GitHub. Mine is called patelhiren.com Create a repository called \u0026lt;username\u0026gt;.github.io. Replace \u0026lt;username\u0026gt; with your GitHub username. Mine is called patelhiren.github.io. Clone your source project via: # adjust to match your git url. git clone git@github.com:patelhiren/patelhiren.com.git Paste your existing source files in the new repository folder.\nRun and verify your local Hugo files from local repo by running hugo server -D and accessing the site at http://localhost:1313/.\nOnce you are happy with the results:\nPress Ctrl+C to kill the server Before proceeding completely remove the public directory Add your public site as a git submodule. Like so:\n# adjust to match your GitHub Pages repo git submodule add -b master git@github.com:patelhiren/patelhiren.github.io.git Automating the deployment process #Create a new file deploy.sh and set its contents to below script. This will allow you to run deploy.sh to build your site and deploy to GitHub in one go.\n#!/bin/sh # If a command fails then the deploy stops set -e printf \u0026#34;\\033[0;32mDeploying updates to GitHub...\\033[0m\\n\u0026#34; # Go To Public folder cd public # Discard local changes on public folder git reset git checkout . git clean -fdx # Pull the latest changes before updating git checkout master git pull origin master cd .. # Garbage collect hugo image-processing generated images. hugo --gc # Build the project. hugo # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # Go To Public folder cd public # Add changes to git. git add . # Commit changes. msg=\u0026#34;rebuilding site $(date)\u0026#34; if [ -n \u0026#34;$*\u0026#34; ]; then msg=\u0026#34;$*\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push origin master Your site will then be available at https://\u0026lt;username\u0026gt;.github.io. Customizing GitHub pages to use a custom domain #If you plan to use your own doamin instead of the \u0026lt;username\u0026gt;.github.io you need to follow the guide at Managing a custom domain for your GitHub Pages site.\nFor my site I did the following:\nCreate a file called CNAME and set its contents to patelhiren.com. Added the CNAME file to the git repo at patelhiren.github.io. Got to Repo Settings at https://github.com/patelhiren/patelhiren.github.io/settings and set Custom domain and Enforce HTTPS settings. GitHub Pages Custom Subdomain Settings Publishing new Post/Changes #To publish a new post:\nCreate a new post similar to to command below. hugo new blog/my-new-post/index.md Set and edit your post using Markdown tools.\nRun and verify your local Hugo files from local repo by running hugo server -D and accessing the site at http://localhost:1313/.\nRun deploy.sh to deploy your site.\nCommit your changes to your source repo.\nConclusion #This is all that should be necessary. It looks like a lot of steps, but in practice it is very simple and doesn\u0026rsquo;t require as much work to maintain for publishing new posts.\nFor a git GUI, I prefer Fork.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCreating a blog post this way with a folder as the post name allows you to keep images within the same folder instead of keeping images in the root folder. This felt like better grouping of content vs the default Hugo suggested way of generating new post via hugo new blog/my-first-post.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI prefer Visual Studio Code. Tip: If using Visual Studio Code you can press CMD+K,V to activate side-by-side live preview of the Markdown you are typing.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"Apr 18, 2020","permalink":"http://localhost:1313/blog/website-built-with-open-source-and-hosted-for-free/","section":"Blogs","summary":"\u003cp\u003eFor a while, I have been considering building a website to document things I learn. This year I decided to stop procsanating and get started with it.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eIntroducing \u003ca href=\"https://patelhiren.com\" title=\"Hiren Patel\u0026#39;s Blog\" target=\"_blank\" rel=\"noreferrer\"\u003epatelhiren.com\u003c/a\u003e in all its glory. \u0026#x1f389;\u003c/strong\u003e\u003c/p\u003e","title":"Building this website using open-source tools and hosting it for free"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/github/","section":"Tags","summary":"","title":"GitHub"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/github-pages/","section":"Tags","summary":"","title":"GitHub Pages"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/hugo/","section":"Tags","summary":"","title":"Hugo"},{"content":"","date":null,"permalink":"http://localhost:1313/categories/patelhiren.com/","section":"Categories","summary":"","title":"Patelhiren.com"},{"content":"When using png files on the web it is often preferred to use tools like pngcrush on them to optimize their size. This is usually a manual process where a command line tool or website is used to process each image file. I decided to automate this process for me via macOS Automator.\nTo crush png images I use the opensource tool PNG Crush.\nIf you have Xcode installed, the pngcrush tool is included as a part of the iOS SDK and there is no additional download required.\nIf you do not have Xcode you may install PNG Crush via Homebrew using the following command.\nbrew install pngcrush If using Xcode method, the pngcrush binary will be at /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/usr/bin/pngcrush.\nIf using Homebrew, the pngcrush binary will be at /usr/local/bin/pngcrush\nFor the rest of the article I will assume the Homebrew method is used. You just need to adjust the paths for the binary if the Xcode method is used.\nTo crush a PNG image via Terminal you can run the below command.\n# pngcrush will process the input.png and create a compressed crushed.png pngcrush input.png crushed.png Automating the process using Automator on macOS. # Launch Automator via Spotlight Search. Select File, New from the menu. Select Quick Action and click the Choose button. In the new windows that loads, select the options as below. Workflow receives current - image files in - Finder.app In the search box, type Shell and select the Run Shell Script option to add to the automation on the right by double clicking on it. Change the Pass Input option to as arguments. Enter the below script commands in the Shell Script box. for f in \u0026#34;$@\u0026#34; do # Verify that the extension of the file is actually png # (case insensitive compare) filename=$(basename \u0026#34;$f\u0026#34;) ext=\u0026#34;${filename##*.}\u0026#34; if echo \u0026#34;$ext\u0026#34; | grep -i png; then # If the file is a png, run pngcrush on it. # Save the output in the same place with a temporary extension # of .crushed_ /opt/homebrew/bin/pngcrush \u0026#34;$f\u0026#34; \u0026#34;$f.crushed_\u0026#34; # Overwrite the original file with the crushed file. mv \u0026#34;$f.crushed_\u0026#34; \u0026#34;$f\u0026#34; fi done Save the automation as PNG Crush. You may now browse to any png file(s) in Finder and right click, select Services -\u0026gt; PNG Crush.\nWhile the automation is running you will see a spinning cog in you Menu bar in the top right. When the cog disappears the automation is done and your images have been processed by pngcrush.\n","date":"Apr 12, 2020","permalink":"http://localhost:1313/blog/pngcrush-automator-action/","section":"Blogs","summary":"\u003cp\u003eWhen using png files on the web it is often preferred to use tools like pngcrush on them to optimize their size. This is usually a manual process where a command line tool or website is used to process each image file. I decided to automate this process for me via macOS \u003ca href=\"https://support.apple.com/guide/automator/welcome/mac\" target=\"_blank\" rel=\"noreferrer\"\u003eAutomator\u003c/a\u003e.\u003c/p\u003e","title":"PNG Crush Automator Action"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/terminal/","section":"Tags","summary":"","title":"Terminal"},{"content":"After upgrading to macOS Catalina (10.15.4), Screensharing via Skype for Business stopped working. Here is waht I did to fix it.\nmacOS Catalina introduced new Privacy settings that prevents Skype for Business screensharing to work if proper permissions are not provided. On trying to start Screensharing via Conversations-\u0026gt;Share Screen option, Skype would display a message stating check the Skype For Business option under System Preferences-\u0026gt;Security \u0026amp; Privacy-\u0026gt;Privacy Tab-\u0026gt;Screen Recording. However navigating there did not display \u0026ldquo;Skype For Business* as an option.\nTo correct it I first reset the \u0026ldquo;Screen Recording\u0026rdquo; permissions for Skype by running this command on Terminal.\ntccutil reset ScreenCapture com.microsoft.SkypeForBusiness If you do not provide the com.microsoft.SkypeForBusiness identifier, the Screen Recording permissions for all apps will be reset and you will have to provide permissions again as needed.\nAfter running that command. I relaunched Skype, selected a Conversation and tried sharing via the screen via the menu option again. I got the same error I got earlier from Skype and no Screen Recording permission prompt was displayed by the OS.\nI had to select the \u0026ldquo;Share Screen\u0026rdquo; icon on the top right of the conversation window. When I tapped that, the OS permissions prompt for Screen Recording came up. I gave the required permission, restarted Skype and was successfully able to share my screen.\nFor the record this was on Skype for Business version 16.28.175.\n","date":"Apr 10, 2020","permalink":"http://localhost:1313/blog/catalina-and-skype-for-business-screensharing/","section":"Blogs","summary":"\u003cp\u003eAfter upgrading to macOS Catalina (10.15.4), Screensharing via Skype for Business stopped working. Here is waht I did to fix it.\u003c/p\u003e","title":"Catalina and Skype for Business Screensharing"},{"content":"","date":null,"permalink":"http://localhost:1313/categories/troubleshooting/","section":"Categories","summary":"","title":"Troubleshooting"},{"content":"I had a spare SSD and a USB enclosure for it. Installing windows on an external drive is unsupported by Microsoft and the setup will abort stating Windows cannot be installed on an external drive. Here is how I managed to install Windows 10 Pro on the external SSD and boot from it on my iMac.\nMy Environment # 27-inch iMac 2019, running macOS Catalina 10.15.4 120 GB ScanDisk Plus SSD 2.5-inch SATA USB enclosure Software needed # VMware Fusion 11.5.3 (Trial is fine) Windows 10 ISO Directions # Launch Disk Utility and select the plugged in SSD. Format as below Disk Utility - Format Disk Make a note of the Disk Id. In my case it was disk5 Create a new Windows 10 Virtual Machine under VMware Fusion. Delete the default Disk the VMware Fusion creates when setting up the machine. Exit VMware Fusion and launch Terminal and run the following command. Adjust the Virtual Manchine path as needed. /Applications/VMware\\ Fusion.app/Contents/Library/vmware-rawdiskCreator \\ create /dev/disk5 \\ fullDevice ~/Virtual\\ Machines.localized/Boot\\ Camp.vmwarevm/external-hdd \\ ide Open Boot Camp.vmx file in a text editor like Visual Studio Code and add the below lines. ide1:0.present = \u0026#34;TRUE\u0026#34; ide1:0.fileName = \u0026#34;external-hdd.vmdk\u0026#34; If you are running macOS Catalina you will need to give Full Disk Access Permissions to com.vmware.DiskHelper. If you do not see it in the list. Try to start the Virtual Machine. You will get an error starting after which the item will show up in the list. Security \u0026 Privacy - Full Disk Access Quit and Restart VMWare fusion. Start the Boot Camp vm. You will be prompted for you admin password. Once the VM starts boot off the Windows 10 ISO and install Windows 10 on the attached disk. Delete all partitions on the disk during install and let windows create new partitions as needed. Once the install is fully finished, install VMware Tools to help facilitate copying of files. On the Mac launch Boot Camp Assistant.app. From the Action menu select Download Windows Support Software. Follow the steps to get the Boot Camp windows drivers. Copy the Drivers to the Windows machine. Shutdown the VM. You may now reboot into the windows partition by rebooting the Mac and holding down the Option key during boot. After Windows boots up, you will have to install the Boot Camp drivers by launching BootCamp setup from the WindowsSupport\\BootCamp\\Setup.exe folder. Additional Steps # After installation of the Boot Camp drivers and reboot, Windows still had a few missing drivers under Device Manager. All I had to do was select Update Driver and select the WindowsSupport\\$WinPEDriver$ folder to look for drivers. Speakers were not working properly on the 2019 iMac even though all drivers were installed. I had to go to Device Manager-\u0026gt;Sound, video and game controllers-\u0026gt;High Definition Audio Device. Select Update driver and point it to WindowsSupport\\$WinPEDriver$\\Cirrus. This installed the correct drivers and the Speakers started working. Another speed bump I ran into was that after a few Windows updates were applied windows declined to update to the November 2019 update stating installing Windows on External USB is unsupported. \u0026#x1f612; I had to go to the Registry at HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control and set the PortableOperatingSystem value to 0 and reboot. After that the update installed ok. \u0026#x1f60f; ","date":"Apr 06, 2020","permalink":"http://localhost:1313/blog/boot-camp-on-external-drive/","section":"Blogs","summary":"\u003cp\u003eI had a spare SSD and a USB enclosure for it. Installing windows on an external drive is unsupported by Microsoft and the setup will abort stating Windows cannot be installed on an external drive. Here is how I managed to install Windows 10 Pro on the external SSD and boot from it on my iMac.\u003c/p\u003e","title":"Boot Camp on External Drive"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/bootcamp/","section":"Tags","summary":"","title":"Bootcamp"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/virtual-machine/","section":"Tags","summary":"","title":"Virtual Machine"},{"content":"I enjoy programming. Besides programming I enjoy reading, listening to podcasts, tinkering with hardware and above all learning new things.\nIn my professional career I have worked on Windows server and client applications as well as iOS and Android mobile applications.\nAt IMM I created software that is used by financial firms to deposit your checks, print your deposit receipts and even apply for your loan online. I pioneered their on premise and cloud eSignature solutions.\nI have also spent some time as an independent and co-founded BitCompute.\nI am currently working as a Sr. Mobile Architect at Systech.\nI also love owning a Tesla because it uses software to provide driving assistance. It being electric is even more amazing. If you are looking to get a Tesla \u0026#x1f697; or Tesla Solar \u0026#x1f506; and would like to use a referral code, I would love it if you used my Tesla Referral Code - hiren90866.\nIf you would like to get in touch you can reach me at @patelhiren or @patelhiren@mastodon.social.\n","date":"Jan 01, 0001","permalink":"http://localhost:1313/about/","section":"Hiren Patel","summary":"\u003cp\u003eI enjoy programming. Besides programming I enjoy reading, listening to podcasts, tinkering with hardware and above all learning new things.\u003c/p\u003e\n\u003cp\u003eIn my professional career I have worked on Windows server and client applications as well as iOS and Android mobile applications.\u003c/p\u003e\n\u003cp\u003eAt \u003ca href=\"https://immonline.com\" title=\"Integrated Media Management - Home Page\" target=\"_blank\" rel=\"noreferrer\"\u003eIMM\u003c/a\u003e I created software that is used by financial firms to deposit your checks, print your deposit receipts and even apply for your loan online. I pioneered their on premise and cloud eSignature solutions.\u003c/p\u003e","title":"👋 🌎, I am Hiren"}]